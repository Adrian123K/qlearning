{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## <b> ■ 복습</b>\n",
    "    1장. 강화학습 개념\n",
    "        강화 + 머신러닝(-> 신경망)\n",
    "        보상을 통해서 학습하는 것\n",
    "        \n",
    "    2장. 강화학습에 필요한 수학용어\n",
    "        MDP(환경, 보상, 행동, 상태전이확률, 감가율)\n",
    "        벨만 방정식\n",
    "            1. 벨만 기대 방정식 -> SARSA (On policy) : 정책 반복\n",
    "            2. 벨만 최적 방정식 -> QLearning (Off policy) : 가치 반복\n",
    "            \n",
    "    3장. 다이나믹 프로그래밍\n",
    "        1. 정책 반복\n",
    "        2. 가치 반복\n",
    "        \n",
    "        다이나믹 프로그래밍과 강화학습의 차이\n",
    "            다이나믹 프로그래밍 : 계산\n",
    "            강화학습 : 학습\n",
    "                \n",
    "    4장. 강화학습\n",
    "        1. SARSA -> 에이전트가 환경을 직접 경험하면서 학습\n",
    "            시간차 학습방법 : 벨만 기대 방정식\n",
    "        2. QLearning -> \n",
    "            벨만 최적 방정식\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4장. 큐러닝 실습 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제1. 큐러닝의 수학식과 코드를 비교해서 확인하세요 ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from environment import Env\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.step_size = 0.01\n",
    "        self.discount_factor = 0.9\n",
    "        self.epsilon = 0.9\n",
    "        self.q_table = defaultdict(lambda: [0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "    # <s, a, r, s'> 샘플로부터 큐함수 업데이트\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        state, next_state = str(state), str(next_state)\n",
    "        q_1 = self.q_table[state][action]\n",
    "        # 벨만 최적 방정식을 사용한 큐함수의 업데이트\n",
    "        q_2 = reward + self.discount_factor * max(self.q_table[next_state])\n",
    "        self.q_table[state][action] += self.step_size * (q_2 - q_1)\n",
    "\n",
    "    # 큐함수에 의거하여 입실론 탐욕 정책에 따라서 행동을 반환\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # 무작위 행동 반환\n",
    "            action = np.random.choice(self.actions)\n",
    "        else:\n",
    "            # 큐함수에 따른 행동 반환\n",
    "            state = str(state)\n",
    "            q_list = self.q_table[state]\n",
    "            action = arg_max(q_list)\n",
    "        return action\n",
    "\n",
    "\n",
    "# 큐함수의 값에 따라 최적의 행동을 반환\n",
    "def arg_max(q_list):\n",
    "    max_idx_list = np.argwhere(q_list == np.amax(q_list))\n",
    "    max_idx_list = max_idx_list.flatten().tolist()\n",
    "    return random.choice(max_idx_list)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = Env()\n",
    "    agent = QLearningAgent(actions=list(range(env.n_actions)))\n",
    "\n",
    "    for episode in range(1000):\n",
    "        state = env.reset()\n",
    "\n",
    "        while True:\n",
    "            # 게임 환경과 상태를 초기화\n",
    "            env.render()\n",
    "            # 현재 상태에 대한 행동 선택\n",
    "            action = agent.get_action(state)\n",
    "            # 행동을 취한 후 다음 상태, 보상 에피소드의 종료여부를 받아옴\n",
    "            next_state, reward, done = env.step(action)\n",
    "            # <s,a,r,s'>로 큐함수를 업데이트\n",
    "            agent.learn(state, action, reward, next_state)\n",
    "\n",
    "            state = next_state\n",
    "            \n",
    "            # 모든 큐함수를 화면에 표시\n",
    "            env.print_value_all(agent.q_table)\n",
    "\n",
    "            if done:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제2.  큐러닝 학습도 아래와 같이 성공과 실패 그리고 epsilon 값이 점점 줄어들게 학습되게 하시오 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from environment import Env\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.step_size = 0.01\n",
    "        self.discount_factor = 0.9\n",
    "        self.epsilon = 0.9\n",
    "        self.q_table = defaultdict(lambda: [0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "    # <s, a, r, s'> 샘플로부터 큐함수 업데이트\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        state, next_state = str(state), str(next_state)\n",
    "        q_1 = self.q_table[state][action]\n",
    "        # 벨만 최적 방정식을 사용한 큐함수의 업데이트\n",
    "        q_2 = reward + self.discount_factor * max(self.q_table[next_state])\n",
    "        self.q_table[state][action] += self.step_size * (q_2 - q_1)\n",
    "\n",
    "    # 큐함수에 의거하여 입실론 탐욕 정책에 따라서 행동을 반환\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # 무작위 행동 반환\n",
    "            action = np.random.choice(self.actions)\n",
    "        else:\n",
    "            # 큐함수에 따른 행동 반환\n",
    "            state = str(state)\n",
    "            q_list = self.q_table[state]\n",
    "            action = arg_max(q_list)\n",
    "        return action\n",
    "\n",
    "\n",
    "# 큐함수의 값에 따라 최적의 행동을 반환\n",
    "def arg_max(q_list):\n",
    "    max_idx_list = np.argwhere(q_list == np.amax(q_list))\n",
    "    max_idx_list = max_idx_list.flatten().tolist()\n",
    "    return random.choice(max_idx_list)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = Env()\n",
    "    agent = QLearningAgent(actions=list(range(env.n_actions)))\n",
    "\n",
    "    cnt_s = 0\n",
    "    cnt_f = 0\n",
    "    for episode in range(1000):\n",
    "        state = env.reset()\n",
    "\n",
    "        while True:\n",
    "            # 게임 환경과 상태를 초기화\n",
    "            env.render()\n",
    "            # 현재 상태에 대한 행동 선택\n",
    "            action = agent.get_action(state)\n",
    "            # 행동을 취한 후 다음 상태, 보상 에피소드의 종료여부를 받아옴\n",
    "            next_state, reward, done = env.step(action)\n",
    "            # <s,a,r,s'>로 큐함수를 업데이트\n",
    "            agent.learn(state, action, reward, next_state)\n",
    "\n",
    "            state = next_state\n",
    "            \n",
    "            # 모든 큐함수를 화면에 표시\n",
    "            env.print_value_all(agent.q_table)\n",
    "\n",
    "            if done:\n",
    "                if reward == 100:\n",
    "                    cnt_s += 1\n",
    "                elif reward == -100:\n",
    "                    cnt_f += 1\n",
    "\n",
    "                if cnt_s != 0 and not cnt_s % 10:\n",
    "                    agent.epsilon -= 0.01\n",
    "                    if agent.epsilon < 0:\n",
    "                        agent.epsilon = 1e-08\n",
    "                print(f\"epsilon : {agent.epsilon} | 성공횟수 : {cnt_s} | 실패횟수 : {cnt_f}\")\n",
    "\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5장. 딥살사 이론 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제1. 만약 아래와 같이 함정이 움직인다면 살사와 큐러닝으로도 에이전트가 목표지점에 갈 수 있을까요?\n",
    "    장애물을 피해가야 하므로 일반 Q함수로는 어렵다.\n",
    "    신경망을 사용해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제2.  이렇게 큐함수를 인공신경망으로 근사하는 알고리즘을 무엇이라 합니까?\n",
    "    DeepSARSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제3. 딥살사의 인공신경망을 업데이트할 때는 경사하강법을 사용해야 합니다. 경사하강법을 이용하려면 오차함수를 정의해야하는데 오차함수는 살사의 큐함수식에서 어느 부분이 정답이고 어느 부분이 예측인가요 ? \n",
    "![f](http://cfile292.uf.daum.net/image/99BC3E4B5F685570308417)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제4. 위의 딥살사 식으로 오차함수를 만들 수 있는데 오차함수식은 어떻게 되나요 ?\n",
    "![f](http://cfile299.uf.daum.net/image/991FE24F5F6856A22C189F)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제5. 기존 살사와 딥살사의 차이가 무엇입니까 ?\n",
    "    SARSA : 현재 상태에서 각 행동에 대한 Q함수를 가져오면 탐욕정책으로 행동 선택\n",
    "    DeepSARSA : Q함수 테이블 대신 인공신경망을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5장. 딥살사 실습문제\n",
    "    \" 딥살사 코드에서 쓰이고 있는 파이썬과 텐써플로우의 새로운 기능 2가지 \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제1. 딥살사 인공신경망을 구현하는 DeepSARSA 클래스에서 파란색 글씨의  super(DeepSARSA, self).__init__()가 무슨뜻 입니까 ?\n",
    "```python\n",
    "# 딥살사 인공신경망\n",
    "class DeepSARSA(tf.keras.Model):\n",
    "    def __init__(self, action_size):\n",
    "        super(DeepSARSA, self).__init__()\n",
    "        self.fc1 = Dense(30, activation='relu')\n",
    "        self.fc2 = Dense(30, activation='relu')\n",
    "        self.fc_out = Dense(action_size)\n",
    "```\n",
    "\n",
    "    상속의 단점인 죽음의 다이아몬드 코드를 개선하기 위한 코드\n",
    "#### 면접문제. 객체지향 언어가 무엇인가? 객체지향 언어의 장점이 무엇인가?\n",
    "    클래스 단위로 코드를 구현하여 클래스를 사용하는 장점을 살린 언어\n",
    "        상속 가능. 상속을 이용하면 부모 클래스에서 구현한 코드를 구현할 필요가 없다.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T02:31:51.002388Z",
     "start_time": "2020-09-22T02:31:50.970469Z"
    }
   },
   "outputs": [],
   "source": [
    "class Card():\n",
    "    def __init__(self):\n",
    "        self.cash = 0\n",
    "        print ('카드가 생성되었습니다')\n",
    "\n",
    "    def charge( self, num):\n",
    "        self.cash += num\n",
    "        print ( self.cash, '원이 충전되었습니다.')\n",
    "\n",
    "    def consume( self, num, place):\n",
    "        if  self.cash >= num:\n",
    "            self.cash -= num\n",
    "            print ( place, '에서 ', num, '원이 사용되었습니다.')\n",
    "            print ( self.cash, '원이 남았습니다') \n",
    "        else:\n",
    "            print ('잔액이 부족합니다.')\n",
    "\n",
    "class Movie_card( Card ):\n",
    "    def consume( self, num, place):\n",
    "        if  place =='영화관':\n",
    "            num = 0.8 * num\n",
    "            if self.cash >= num:\n",
    "                self.cash -= num\n",
    "                print ('%s 에서 %d 사용했습니다' %(place, num) )\n",
    "            else:\n",
    "                print ('잔액이 부족합니다')\n",
    "        else:\n",
    "            if self.cash >= num:\n",
    "                self.cash -= num\n",
    "                print ('%s 에서 %d 사용했습니다.' %(place, num) ) \n",
    "            else:\n",
    "                print ('잔액이 부족합니다.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    상속의 장점은 부모클래스의 유산을 물려받았으면 자식 클래스에서는 굳이 부모클래스의 코드를 코딩하지 않아도 됩니다.  다만 한가지 유의해야할 사항이 있는데 그게 다중 상속의 죽음의 다이아몬드 입니다..  아래의 코드를 실행해보세요 ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T02:31:55.074951Z",
     "start_time": "2020-09-22T02:31:55.058022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "튼튼한 두팔\n",
      "지식\n",
      "튼튼한 두팔\n",
      "지혜\n",
      "자기 만족도가 높은 삶\n"
     ]
    }
   ],
   "source": [
    "class Grandfather:\n",
    "    def __init__(self):\n",
    "        print('튼튼한 두팔')\n",
    "\n",
    "class Father1(Grandfather):\n",
    "    def __init__(self):\n",
    "        Grandfather.__init__(self)\n",
    "        print('지식')\n",
    "\n",
    "class Father2(Grandfather):\n",
    "    def __init__(self):\n",
    "        Grandfather.__init__(self)\n",
    "        print('지혜')\n",
    "        \n",
    "class Grandchild(Father1, Father2):\n",
    "    def __init__(self):\n",
    "        Father1.__init__(self)\n",
    "        Father2.__init__(self)\n",
    "        print('자기 만족도가 높은 삶')\n",
    "        \n",
    "grandchild=Grandchild()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    팔이 4개가 되어버렸습니다.  \n",
    "    이 문제를 해결하기 위해서 파이썬에서는 다음과 같은 코드를 제공합니다.\n",
    "#### 문제2. 위의 문제를 해결하려면 어떻게 해야합니까 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T02:41:44.929612Z",
     "start_time": "2020-09-22T02:41:44.913647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "튼튼한 두팔\n",
      "지혜\n",
      "지식\n",
      "자기 만족도가 높은 삶\n"
     ]
    }
   ],
   "source": [
    "class Grandfather:\n",
    "    def __init__(self):\n",
    "        print('튼튼한 두팔')\n",
    "\n",
    "class Father1(Grandfather):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print('지식')\n",
    "\n",
    "class Father2(Grandfather):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print('지혜')\n",
    "        \n",
    "class Grandchild(Father1, Father2):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print('자기 만족도가 높은 삶')\n",
    "        \n",
    "grandchild=Grandchild()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ■ 죽음의 다이아몬드 상속을 해결하기 위한 다른 기능은 ?\n",
    "![f](http://cfile290.uf.daum.net/image/9948F44D5F68623F05E55C)\n",
    "    \n",
    "    D 클래스가 B와 C 클래스를 상속 받고, B와 C 클래스는 같은 부모 클래스인 A 클래스를 상속 받는 형태입니다. \n",
    "    이때, D 클래스를 호출하게 되면 어떤 현상이 일어나게 될까요?\n",
    "    D는 B를 상속받았으니, B의 생성자가 한번 실행되며  \n",
    "    B는 A를 상속 받았으니, A의 생성자를 실행할 것입니다.\n",
    "    또한 D는 C도 상속받았으니, C의 생성자를 한번 실행하며,  \n",
    "    C는 또 A를 상속 받았으니, A의 생성자를 실행할 것입니다. \n",
    "\n",
    "    즉, A의 생성자는 두번 호출 되는 꼴입니다. \n",
    "    아래의 코드를 실행해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T02:44:09.638729Z",
     "start_time": "2020-09-22T02:44:09.626765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class D __init__()\n",
      "Class B __init__()\n",
      "Class A __init__()\n",
      "Class C __init__()\n",
      "Class A __init__()\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"Class A __init__()\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class B __init__()\")\n",
    "        A.__init__(self)\n",
    "\n",
    "class C(A):\n",
    "    def __init__(self):\n",
    "        print(\"Class C __init__()\")\n",
    "        A.__init__(self)\n",
    "\n",
    "class D(B, C):\n",
    "    def __init__(self):\n",
    "        print(\"Class D __init__()\")\n",
    "        B.__init__(self)\n",
    "        C.__init__(self)\n",
    "\n",
    "d = D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A의 생성자는 두번 호출 되었습니다. 위와 같은 문제를 어떻게 해결할 수 있을까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T03:07:15.105768Z",
     "start_time": "2020-09-22T03:07:15.094796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class C __init__()\n",
      "Class A __init__()\n",
      "Class B __init__()\n",
      "순서B\n",
      "순서C\n",
      "Class D __init__()\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        super(A, self).__init__()\n",
    "        print(\"Class A __init__()\")\n",
    "        \n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        super(B, self).__init__()\n",
    "        print(\"Class B __init__()\")\n",
    "#         super(B, self).__init__()\n",
    "        print(\"순서B\")\n",
    "\n",
    "class C(A):\n",
    "    def __init__(self):\n",
    "#         super(C, self).__init__()\n",
    "        print(\"Class C __init__()\")\n",
    "        super(C, self).__init__()\n",
    "        print(\"순서C\")\n",
    "\n",
    "class D(C, B):\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "        print(\"Class D __init__()\")\n",
    "#         super(D, self).__init__()\n",
    "\n",
    "d = D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ (점심시간 문제) 아래의 코드의 다중 상속의 죽음의 다이아몬드 문제를 두번째 방법으로 해결하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T03:12:03.766426Z",
     "start_time": "2020-09-22T03:12:03.754462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "튼튼한 두팔\n",
      "지혜\n",
      "지식\n",
      "자기 만족도가 높은 삶\n"
     ]
    }
   ],
   "source": [
    "class Grandfather:\n",
    "    def __init__(self):\n",
    "        print('튼튼한 두팔')\n",
    "        \n",
    "class Father1(Grandfather):\n",
    "    def __init__(self):\n",
    "        super(Father1,self).__init__()\n",
    "        print('지식')\n",
    "\n",
    "class Father2(Grandfather):\n",
    "    def __init__(self):\n",
    "        super(Father2,self).__init__()\n",
    "        print('지혜')\n",
    "\n",
    "class Grandchild(Father1, Father2):\n",
    "    def __init__(self):\n",
    "        super(Grandchild,self).__init__()\n",
    "        print('자기 만족도가 높은 삶')\n",
    "\n",
    "grandchild=Grandchild()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제3. 딥살사 클래스 함수중 train_model 함수의 tf.GradientTape() 가 무엇인가요? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
